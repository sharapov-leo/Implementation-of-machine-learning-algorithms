{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning classification algorithms\n",
    "\n",
    "Data source: https://www.kaggle.com/aiaiaidavid/cardio-data-dv13032020\n",
    "\n",
    "The dataframe describes the state of a person and his bad habits.\n",
    "A true value in the last column of 'CARDIO_DISEASE' means that the person has cardio disease.\n",
    "\n",
    "It is required to determine whether a person has a cardio disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a comma-separated value (csv) file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "dataframe = pandas.read_csv(\"out.csv\")\n",
    "dataframe = dataframe[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the first 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>AP_HIGH</th>\n",
       "      <th>AP_LOW</th>\n",
       "      <th>CHOLESTEROL</th>\n",
       "      <th>GLUCOSE</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>ALCOHOL</th>\n",
       "      <th>PHYSICAL_ACTIVITY</th>\n",
       "      <th>CARDIO_DISEASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  GENDER  HEIGHT  WEIGHT  AP_HIGH  AP_LOW  CHOLESTEROL  GLUCOSE  SMOKE  \\\n",
       "0   50       2     168      62      110      80            1        1      0   \n",
       "1   55       1     156      85      140      90            3        1      0   \n",
       "2   52       1     165      64      130      70            3        1      0   \n",
       "3   48       2     169      82      150     100            1        1      0   \n",
       "4   48       1     156      56      100      60            1        1      0   \n",
       "\n",
       "   ALCOHOL  PHYSICAL_ACTIVITY  CARDIO_DISEASE  \n",
       "0        0                  1               0  \n",
       "1        0                  1               1  \n",
       "2        0                  0               1  \n",
       "3        0                  1               1  \n",
       "4        0                  0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = dataframe.drop(\"CARDIO_DISEASE\",axis=1).to_numpy()\n",
    "X = StandardScaler().fit_transform(X) \n",
    "\n",
    "y = dataframe[\"CARDIO_DISEASE\"].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for fitting and evaluating machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calc(model, X, y, n_splits=10, average='binary'):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "    precision = np.empty(n_splits, dtype=float)\n",
    "    recall = np.empty(n_splits, dtype=float)\n",
    "    accuracy = np.empty(n_splits, dtype=float)\n",
    "    f1 = np.empty(n_splits, dtype=float)\n",
    "    for i, (train_indexes, true_indexes) in enumerate(skf.split(X, y)):\n",
    "        X_train = X[train_indexes]\n",
    "        y_train = y[train_indexes]        \n",
    "        X_true = X[true_indexes]\n",
    "        y_true = y[true_indexes]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_true)\n",
    "        \n",
    "        precision[i] = precision_score(y_true, y_pred, average=average)\n",
    "        recall[i] = recall_score(y_true, y_pred, average=average)\n",
    "        accuracy[i] = accuracy_score(y_true, y_pred)\n",
    "        f1[i] = f1_score(y_true, y_pred, average=average)\n",
    "    return [precision, recall, accuracy, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import basic machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model # LogisticRegression\n",
    "from sklearn import neighbors # KNeighborsClassifier\n",
    "from sklearn import svm # SVC\n",
    "from sklearn import tree # DecisionTreeClassifier\n",
    "from sklearn import ensemble # RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, eta=1, max_iter=10, fit_intercept=True):\n",
    "        self.eta = eta # learning rate\n",
    "        self.max_iter = max_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((ones, X), axis=1)\n",
    "        return X\n",
    "        \n",
    "    def sigmoid(self, X):\n",
    "        return 1.0 / (1.0 + np.exp(-X))\n",
    "    \n",
    "    def fit(self, X, y):   \n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        m = X.shape[0] # number of records\n",
    "        n = X.shape[1] # number of features\n",
    "        self.theta = np.random.randn(n) # weights        \n",
    "        for i in range(self.max_iter):\n",
    "            h = self.sigmoid(np.dot(X, self.theta))\n",
    "            grad = 2 * np.dot(X.T, (h - y)) / m\n",
    "            self.theta -= self.eta * grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        y_pred = np.dot(X, self.theta)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "        y_pred = np.where(y_pred >= 0.5,1,0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression from sklearn.linear_model\n",
      "Precision score is 0.771 (+- 0.040)\n",
      "Recall score is 0.672 (+- 0.056)\n",
      "Accuracy score is 0.736 (+- 0.035)\n",
      "F1 score is 0.717 (+- 0.042)\n",
      "\n",
      "My implementation of logistic regression\n",
      "Precision score is 0.748 (+- 0.031)\n",
      "Recall score is 0.684 (+- 0.072)\n",
      "Accuracy score is 0.726 (+- 0.032)\n",
      "F1 score is 0.712 (+- 0.043)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression(solver='sag')\n",
    "metrics = metrics_calc(lr, X, y)\n",
    "print(\"Logistic regression from sklearn.linear_model\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "metrics = metrics_calc(lr, X, y)\n",
    "print(\"My implementation of logistic regression\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier():\n",
    "    def __init__(self, n_neighbors=20):\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def distanceMetric(self, x, y):\n",
    "        nx = x.size\n",
    "        d = sum(abs(x[i] - y[i]) for i in range(nx))\n",
    "        return d\n",
    "    \n",
    "    def predict(self, X_true):\n",
    "        classes = list(set(self.y))\n",
    "        m_train = self.X.shape[0] # X_train\n",
    "        m_true = X_true.shape[0]\n",
    "        n = X_true.shape[1]\n",
    "        y_pred = np.empty(m_true)\n",
    "        for i in range(m_true): # m\n",
    "            D = [self.distanceMetric(X_true[i], x) for x in self.X] # m\n",
    "            indices = np.argsort(D)\n",
    "            indices = indices[:self.n_neighbors]\n",
    "            num_objs_of_each_class = [np.sum(self.y[indices] == c) for c in classes]\n",
    "            position = np.argmax(num_objs_of_each_class)\n",
    "            y_pred[i] = classes[position]\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating k-Nearest Neighbors models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-nearest neighbors from sklearn.neighbors\n",
      "Precision score is 0.696 (+- 0.042)\n",
      "Recall score is 0.648 (+- 0.057)\n",
      "Accuracy score is 0.682 (+- 0.038)\n",
      "F1 score is 0.670 (+- 0.044)\n",
      "\n",
      "My implementation of k-nearest neighbors\n",
      "Precision score is 0.693 (+- 0.056)\n",
      "Recall score is 0.650 (+- 0.075)\n",
      "Accuracy score is 0.680 (+- 0.047)\n",
      "F1 score is 0.669 (+- 0.055)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "metrics = metrics_calc(knn, X, y)\n",
    "print(\"K-nearest neighbors from sklearn.neighbors\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "metrics = metrics_calc(knn, X, y)\n",
    "print(\"My implementation of k-nearest neighbors\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing support vector machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class SVM:\n",
    "    def __init__(self, alpha=0.001, eta=0.1, max_iter=50, tol=0.0001, fit_intercept=True):\n",
    "        self.alpha = alpha\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X):\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        X = np.concatenate((ones, X), axis=1)\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y, verbose=False):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        y = np.where(y,1,-1)\n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "        self.theta = np.random.randn(n)        \n",
    "        prev_loss = math.inf\n",
    "        for iteration in range(self.max_iter):\n",
    "            loss = 0\n",
    "            for i, x in enumerate(X):\n",
    "                margin = y[i] * np.dot(x, self.theta)\n",
    "                grad = self.alpha * self.theta / self.max_iter\n",
    "                if margin < 1:\n",
    "                    grad -= y[i] * x\n",
    "                self.theta -= self.eta * grad\n",
    "                loss += self.soft_margin_loss(x, y[i])\n",
    "            if abs(prev_loss - loss) <= self.tol:\n",
    "                return\n",
    "            prLoss = loss\n",
    "            \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        y_pred = np.sign(np.dot(X, self.theta))\n",
    "        y_pred = np.where(y_pred == 1,1,0)\n",
    "        return y_pred   \n",
    "    \n",
    "    def hinge_loss(self, X, y):\n",
    "        return max(0, 1 - np.dot(y, np.dot(X, self.theta)))\n",
    "    \n",
    "    def soft_margin_loss(self, X, y):\n",
    "        return self.hinge_loss(X, y) + self.alpha * np.dot(self.theta, self.theta) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating support vector machine (SVM) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector from sklearn.svm\n",
      "Precision score is 0.764 (+- 0.048)\n",
      "Recall score is 0.626 (+- 0.048)\n",
      "Accuracy score is 0.715 (+- 0.032)\n",
      "F1 score is 0.687 (+- 0.037)\n",
      "\n",
      "My implementation of support vector\n",
      "Precision score is 0.691 (+- 0.049)\n",
      "Recall score is 0.696 (+- 0.062)\n",
      "Accuracy score is 0.691 (+- 0.047)\n",
      "F1 score is 0.692 (+- 0.047)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sv = svm.SVC(kernel='poly')\n",
    "metrics = metrics_calc(sv, X, y)\n",
    "print(\"Support vector from sklearn.svm\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))\n",
    "\n",
    "sv = SVM()\n",
    "metrics = metrics_calc(sv, X, y)\n",
    "print(\"My implementation of support vector\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, predicted_class):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.column = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, max_depth=20):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def split(self, X, y, num_parent_objs):\n",
    "        m = X.shape[0]\n",
    "        min_gini = 1.0 - sum((x / m) ** 2 for x in num_parent_objs)\n",
    "        col_split, threshold_split = None, None\n",
    "        for col in self.columns:\n",
    "            indices = np.argsort(X[:, col])\n",
    "            thresholds = X[:, col][indices]\n",
    "            classes = y[indices]\n",
    "            num_left_objs = np.zeros(len(self.classes))\n",
    "            num_right_objs = num_parent_objs.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left_objs[c] += 1\n",
    "                num_right_objs[c] -= 1\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                gini_left = 1.0 - sum((x / i) ** 2 for x in num_left_objs)\n",
    "                gini_right = 1.0 - sum((x / (m - i)) ** 2 for x in num_right_objs)\n",
    "                gini = i * gini_left / m + (m - i) * gini_right / m\n",
    "                if min_gini > gini:\n",
    "                    min_gini = gini\n",
    "                    col_split = col\n",
    "                    threshold_split = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return col_split, threshold_split\n",
    "        \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        num_objs = [np.sum(y == i) for i in self.classes]        \n",
    "        predicted_class = np.argmax(num_objs)\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "        if depth < self.max_depth:\n",
    "            col_split, threshold_split = self.split(X, y, num_parent_objs=num_objs)\n",
    "            if col_split:\n",
    "                node.column = col_split\n",
    "                node.threshold = threshold_split\n",
    "                indices_left = np.where(X[:, col_split] < threshold_split)\n",
    "                indices_right = np.where(X[:, col_split] >= threshold_split)\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[indices_right], y[indices_right]\n",
    "                node.left = self.build_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self.build_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classes = set(y)\n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "        self.columns = np.random.randint(low=0, high=n-1, size=n)\n",
    "        size = np.random.randint(low=2,high=m-1)\n",
    "        indices = np.random.randint(low=0, high=m-1, size=size)\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def iterative_tree_search(self, row):\n",
    "        node = self.root\n",
    "        while node.left:\n",
    "            if row[node.column] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = np.array([self.iterative_tree_search(row) for row in X])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating decision tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree from sklearn.tree\n",
      "Precision score is 0.673 (+- 0.022)\n",
      "Recall score is 0.664 (+- 0.067)\n",
      "Accuracy score is 0.670 (+- 0.021)\n",
      "F1 score is 0.666 (+- 0.034)\n",
      "\n",
      "My implementation of decision tree\n",
      "Precision score is 0.772 (+- 0.091)\n",
      "Recall score is 0.558 (+- 0.122)\n",
      "Accuracy score is 0.689 (+- 0.054)\n",
      "F1 score is 0.635 (+- 0.088)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier(max_depth=20)\n",
    "metrics = metrics_calc(dt, X, y)\n",
    "print(\"Decision tree from sklearn.tree\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=20)\n",
    "metrics = metrics_calc(dt, X, y)\n",
    "print(\"My implementation of decision tree\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier():\n",
    "    def __init__(self, max_depth=20, n_estimators=20):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_estimators = n_estimators\n",
    "        self.forest = [DecisionTreeClassifier(max_depth=self.max_depth) for i in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = set(y)\n",
    "        for i in range(self.n_estimators):\n",
    "            self.forest[i].fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]\n",
    "        y_preds = np.array([self.forest[i].predict(X) for i in range(self.n_estimators)])\n",
    "        y_pred = np.empty(m, dtype=int)\n",
    "        for i in range(m):\n",
    "            num_objs = [np.sum(y_preds.T[i] == j) for j in self.classes]\n",
    "            predicted_class = np.argmax(num_objs)\n",
    "            y_pred[i] = predicted_class\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and evaluating random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest from sklearn.ensemble\n",
      "Precision score is 0.772 (+- 0.091)\n",
      "Recall score is 0.558 (+- 0.122)\n",
      "Accuracy score is 0.689 (+- 0.054)\n",
      "F1 score is 0.635 (+- 0.088)\n",
      "\n",
      "My implementation of random forest\n",
      "Precision score is 0.811 (+- 0.086)\n",
      "Recall score is 0.560 (+- 0.069)\n",
      "Accuracy score is 0.708 (+- 0.021)\n",
      "F1 score is 0.656 (+- 0.029)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = ensemble.RandomForestClassifier(max_depth=20, n_estimators=5)\n",
    "rf = metrics_calc(rf, X, y)\n",
    "print(\"Random forest from sklearn.ensemble\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=20, n_estimators=5)\n",
    "metrics = metrics_calc(rf, X, y)\n",
    "print(\"My implementation of random forest\")\n",
    "print(\"Precision score is %0.3f (+- %0.3f)\"%(metrics[0].mean(), metrics[0].std()))\n",
    "print(\"Recall score is %0.3f (+- %0.3f)\"%(metrics[1].mean(), metrics[1].std()))\n",
    "print(\"Accuracy score is %0.3f (+- %0.3f)\"%(metrics[2].mean(), metrics[2].std()))\n",
    "print(\"F1 score is %0.3f (+- %0.3f)\\n\"%(metrics[3].mean(), metrics[3].std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
